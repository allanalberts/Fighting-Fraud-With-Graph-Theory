{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working notebook\n",
    "\n",
    "### Utility Functions:\n",
    "- load_bitcoin_edge_data(filename)\n",
    "- user_activity_dataframe(bitcoin_df) <-- uses user_stats(bitcoin_df)\n",
    "- build_graph(bitcoin_df, user_lst=[], rating_type='all', maxdate='2016-01-24')\n",
    "#### visualization functions:\n",
    "- plot_timeline(bitcoin_df, title)\n",
    "- add_user_to_graph(existing_graph, new_user, bitcoin_df)\n",
    "\n",
    "### EDA Learnings:\n",
    "alpha network does not have time level timestamp so cannot do velocity or bot analysis\n",
    "or sort chronologically within a day\n",
    "\n",
    "### Interesting Fraud Examples:\n",
    "otc_user = '2680'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import networkx as nx\n",
    "import nxpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import helpers as h\n",
    "import visualizations as v\n",
    "import model as m\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "otc_df = h.load_bitcoin_edge_data('../data/soc-sign-bitcoinotc.csv.gz')\n",
    "alpha_df = h.load_bitcoin_edge_data('../data/soc-sign-bitcoinalpha.csv.gz')\n",
    "alpha_users = h.user_activity_dataframe(alpha_df)\n",
    "otc_users = h.user_activity_dataframe(otc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph objects\n",
    "_ , alpha_G = h.build_graph(alpha_df)\n",
    "_ , alpha_pos_G = h.build_graph(alpha_df, rating_type='pos')\n",
    "_ , otc_G = h.build_graph(otc_df)\n",
    "_ , otc_pos_G = h.build_graph(otc_df, rating_type='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v.plot_timeline(alpha_df, 'Alpha Bit Coin Ratings Activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v.plot_timeline(otc_df, 'OTC Bit Coin Ratings Activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # date velocity\n",
    "# start_time = time.time()\n",
    "# df_dv = m.feature_iteration_date_velocity(alpha_df)\n",
    "# print(f\"{(time.time() - start_time):.0f} seconds execution time\")\n",
    "\n",
    "# # Save File\n",
    "# df_dv.to_csv('../data/df_dv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve File\n",
    "df_dv = pd.read_csv('../data/df_dv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 seconds execution time\n"
     ]
    }
   ],
   "source": [
    "# sequential velocity\n",
    "\n",
    "# looks for sequential negative ratings activity\n",
    "# neg_cnt_last_1_rating\n",
    "# neg_cnt_last_2_rating\n",
    "# neg_cnt_last_3_rating\n",
    "\n",
    "start_time = time.time()\n",
    "df_sv = m.feature_iteration_sequential_velocity(alpha_df)\n",
    "print(f\"{(time.time() - start_time):.0f} seconds execution time\")\n",
    "\n",
    "# Save File\n",
    "df_sv.to_csv('../data/df_sv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve File\n",
    "df_sv = pd.read_csv('../data/df_sv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Features\n",
    "\n",
    "- collusion features\n",
    "- retalitory rating features - see node 95-188-7 (when you run 7604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 seconds execution time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/var/folders/b3/m0fdz7_d6sz58yt6vfj9mfc40000gn/T/nx_l61a5wu_.png'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse view to see the network of who is rating this guy\n",
    "# use census type or sometbing else for feature?\n",
    "start_time = time.time()\n",
    "_, g = h.build_graph(alpha_df[alpha_df['rating']>0])#, maxdate=rate_date)\n",
    "\n",
    "# both directions --> use undirected=True\n",
    "# in direction --> use reverse_view()\n",
    "# test_g = nx.ego_graph(nx.reverse_view(g), 7604, radius=1)\n",
    "#test_g = nx.ego_graph(g, 7604, undirected=True, radius=1)\n",
    "test_g = nx.ego_graph(nx.reverse_view(g), 7604, center=False, undirected=True, radius=1)\n",
    "node_census = nx.triadic_census(test_g)\n",
    "print(f\"{(time.time() - start_time):.0f} seconds execution time\")\n",
    "# nx.draw_shell(test_g )\n",
    "node_census\n",
    "nxpd.draw(test_g )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'003': 282,\n",
       " '012': 166,\n",
       " '102': 64,\n",
       " '021D': 0,\n",
       " '021U': 69,\n",
       " '021C': 4,\n",
       " '111D': 38,\n",
       " '111U': 6,\n",
       " '030T': 21,\n",
       " '030C': 0,\n",
       " '201': 2,\n",
       " '120D': 11,\n",
       " '120U': 7,\n",
       " '120C': 1,\n",
       " '210': 8,\n",
       " '300': 1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networkx Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_GU = alpha_G.to_undirected()\n",
    "nx.number_of_cliques(alpha_GU, nodes=7551)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the triadic census\n",
    "census = nx.triadic_census(alpha_G)\n",
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triad generator\n",
    "triads = all_triads(alpha_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_census = nx.triads_by_type(alpha_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=node_census.values()[1].keys() \n",
    "\n",
    "## Generate a table header\n",
    "print('| Node |', ' | '.join(keys))\n",
    "for k in node_census.keys(): \n",
    "     print('|', k, '|',' | '.join([str(v) for v in node_census[k].values()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connected_component_subgraphs() returns a list of components,\n",
    "# sorted largest to smallest\n",
    "components=nx.connected_component_subgraphs(alpha_G)\n",
    "# pick the first and largest component\n",
    "cc = components[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community\n",
    "\n",
    "communities_generator = community.girvan_newman(alpha_G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "\n",
    "sorted(map(sorted, top_level_communities))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Girvan–Newman algorithm detects communities by progressively removing edges from the original graph. The algorithm removes the “most valuable” edge, traditionally the edge with the highest betweenness centrality, at each step. As the graph breaks down into pieces, the tightly knit community structure is exposed and the result can be depicted as a dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx.generators.small\n",
    "\n",
    "g = networkx.generators.small.krackhardt_kite_graph()\n",
    "\n",
    "g.adjacency_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otc_users[otc_users['BotActivity']==True].sort_values('TimeActive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to create visualization to Define Bot acitivity\n",
    "In Alpha network only bot activity is with zero time delay - all same day raters\n",
    "In OTC network only 18 users have zero time delay, however, XXX\n",
    "users have delay under 1? minute (what is delay )\n",
    "\n",
    "need 3 eda plots of same day rater distribution - day by hour, hour by minute, minute by second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Alpha Bot users: {alpha_users['BotActivity'].sum()}\")\n",
    "print(f\"OTC Bot users: {otc_users['BotActivity'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/alpha_with_ratee_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ato = m.feature_iteration_ato(alpha_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ato.reset_index(drop=True, inplace=True)\n",
    "df_ato.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_ato], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "X = df.copy()\n",
    "X = X.drop(['rater', 'ratee', 'rating','date', 'color', 'penwidth', 'binomial_rating'], axis=1)\n",
    "y = X.pop('class')\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, shuffle=True,\n",
    "                                                    random_state=123)\n",
    "\n",
    "RF = RandomForestClassifier(n_jobs=-1, random_state=123)\n",
    "RF.fit(X_train, y_train)\n",
    "y_preds = RF.predict(X_test)\n",
    "recall = recall_score(y_test, y_preds)\n",
    "precision = precision_score(y_test, y_preds)\n",
    "\n",
    "# print(X_test[(y_preds==0) & (X_test['num_neg_received']>0)].head(10))\n",
    "print(recall)\n",
    "print(precision)\n",
    "RF.feature_importances_\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "name = \"Random Forest\"\n",
    "indices = np.argsort(RF.feature_importances_)[::-1][:40]\n",
    "ax1 = sns.barplot(y=X_train.columns[indices][:40],x = RF.feature_importances_[indices][:40] , orient='h')\n",
    "ax1.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "ax1.set_ylabel(\"Features\",fontsize=12)\n",
    "ax1.tick_params(labelsize=9)\n",
    "ax1.set_title(name + \" feature importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "thresh = 0.2\n",
    "pred_proba = RF.predict_proba(X_test)[:,1]\n",
    "cnf_matrix = confusion_matrix(y_test, pred_proba>=thresh)\n",
    "print(cnf_matrix)\n",
    "tn, fp, fn, tp = cnf_matrix.ravel()\n",
    "tn, fp, fn, tp\n",
    "neg = tn + fp\n",
    "pos = fn + tp\n",
    "tnpct = tn/neg\n",
    "fppct = fp/neg\n",
    "fnpct = fn/pos\n",
    "tppct = tp/pos\n",
    "cnt_matrix_pct = np.round(np.array([tnpct,fppct,fnpct, tppct]), 2)\n",
    "cnt_matrix_pct.reshape((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[y_test-y_preds].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test-y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[22765]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[22765]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, prediction, label in zip(X_test, y_preds, y_test):\n",
    "    if prediction != label:\n",
    "        print(input, 'has been classified as ', prediction, 'and should be ', label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(ax, cm, title, classes=['Legitimate','Fraud'],\n",
    "                          cmap=plt.cm.Blues, currency=False):\n",
    "    \"\"\"\n",
    "    Plots a single confusion matrix. If currency=True then displays results as currency.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cm: array (confusion matrix)\n",
    "    title: String\n",
    "    test_size: float - size/percentage of holout dataset\n",
    "    goal: float - project goal for ultimate dollar loss rate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"   \n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        cost=cm[i, j]\n",
    "        if currency:\n",
    "            cost = f'${cost:0,.2f}' \n",
    "        ax.text(j, i, cost, horizontalalignment=\"center\", \n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    if currency:\n",
    "        ax.set_title(f'{title}\\nCost Matrix')\n",
    "    else:\n",
    "        ax.set_title(f'{title}\\nConfusion Matrix')\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_xticklabels(classes, rotation=0)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(classes, rotation=90)\n",
    "\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "fig, ax = plt.subplots()\n",
    "plot_confusion_matrix(ax, cnf_matrix, \"test\", classes=['Pos Rating','Neg Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Make function for indivisual plot and then you can call it over and over\n",
    "def Plot_PR_Curve(X, y):\n",
    "    '''\n",
    "    Calculates and Plots PR Curve and puts threshold marker on curve.\n",
    "    '''\n",
    "    # get points to plot on the PR Curve\n",
    "    thresh = 0.5\n",
    "    precision, recall, thresholds = precision_recall_curve(y, pred_proba) \n",
    "        \n",
    "    # find the index of the record with closest threshold to desired threshold value\n",
    "    threshold_idx = np.argmin(np.abs(thresholds-thresh))\n",
    "    \n",
    "    plt.plot(precision, recall)\n",
    "    plt.plot(precision, threshold_idx, recall, threshold_idx, 'o', \n",
    "             markersize=10, fillstyle='full', \n",
    "             label=\"{thresh:.2f} threshold\", mew=2)\n",
    "\n",
    "    plt.legend(loc='center', frameon=False)\n",
    "    plt.title('Precision-Recall Curve Comparison')    \n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlim(xmin=-0.05,xmax=1.05);\n",
    "    plt.ylim(ymin=-0.05,ymax=1.05);  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_PR_Curve(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding dimension to 14, the number of walks to 25, and the number of iterations to 15.\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "# Precompute probabilities and generate walks\n",
    "# node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "node2vec = Node2Vec(G, dimensions=14, walk_length=30, num_walks=25, workers=4)\n",
    "\n",
    "# Embed\n",
    "# windows is the number of max distance from the node that the vector is going to be based on\n",
    "# maybe i can move this to 1 or 2??\n",
    "model = node2vec.fit(window=5, min_count=1)#, batch_words=4)  # Any keywords acceptable by gensim.Word2Vec can be passed, `diemnsions` and `workers` are automatically passed (from the Node2Vec constructor)\n",
    "\n",
    "# Look for most similar nodes\n",
    "model.wv.most_similar('2')  # Output node names are always strings\n",
    "\n",
    "# giving me 10 most similar to user\n",
    "user = '1006'\n",
    "model.wv.most_similar(user) \n",
    "\n",
    "# gives 64 length vector for user\n",
    "vector = model.wv[user]\n",
    "print(vector)\n",
    "\n",
    "embeddingsframe = pd.DataFrame(model.get_embedding())\n",
    "\n",
    "n = [] # node list?\n",
    "e = [] # embeddings list\n",
    "\n",
    "with open('./trimmed_network.emb') as fin:\n",
    "    for line in model:\n",
    "        node_emb = line.strip().split()  # turns into a list and removes white spaces at beginning and ending of string\n",
    "        n.append(node_emb[0])\n",
    "        e.append(node_emb[1:])\n",
    "\n",
    "n = n[1:]\n",
    "n = [int(i) for i in n] #  converts node to an int datatype\n",
    "embs = np.zeros([len(e)-1,14])\n",
    "for i in range(1,len(e)):\n",
    "    embs[i-1] = e[i]\n",
    "embs.shape\n",
    "\n",
    "# Save embeddings for later use\n",
    "model.wv.save_word2vec_format(EMBEDDING_FILENAME)\n",
    "\n",
    "# Save model for later use\n",
    "model.save(EMBEDDING_MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_velocity(bitcoin_df, user, rate_date, vel_parm, user_type):\n",
    "    df = bitcoin_df.copy()\n",
    "    from_date = str(pd.Timestamp(rate_date) - pd.offsets.Hour(vel_parm))\n",
    "    vel_neg, vel_all = \\\n",
    "    df[(df[user_type]==user) & (df['date'] <= rate_date) & (df['date'] > from_date)]['class'].agg(['sum', 'count'])\n",
    "    vel_pos = vel_all - vel_neg\n",
    "    A = np.array([vel_neg, vel_pos, vel_all])\n",
    "    A[np.isnan(A)] = 0\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def feature_iteration_date_velocity(bitcoin_df):\n",
    "    start_time = time.time()\n",
    "    df = bitcoin_df.copy()\n",
    "    df = df[['ratee', 'rater', 'rating','date','class']]\n",
    "    for i, row in df.iterrows():\n",
    "        user = row['ratee']\n",
    "        rate_date = row['date']\n",
    "        vel_24_in_neg, vel_24_in_pos, vel_24_in_all = velocity(df, user, rate_date, vel_parm=24, user_type=\"ratee\")\n",
    "        vel_24_out_neg, vel_24_out_pos, vel_24_out_all = velocity(df, user, rate_date, vel_parm=24, user_type=\"rater\")\n",
    "        vel_48_in_neg, vel_48_in_pos, vel_48_in_all = velocity(df, user, rate_date, vel_parm=48, user_type=\"ratee\")\n",
    "        vel_48_out_neg, vel_48_out_pos, vel_48_out_all = velocity(df, user, rate_date, vel_parm=48, user_type=\"rater\")\n",
    "        df.at[(i,'vel_24_in_pos')] = vel_24_in_pos\n",
    "        df.at[(i,'vel_24_in_neg')] = vel_24_in_neg\n",
    "        df.at[(i,'vel_24_in_all')] = vel_24_in_all\n",
    "        df.at[(i,'vel_24_out_pos')] = vel_24_out_pos\n",
    "        df.at[(i,'vel_24_out_neg')] = vel_24_out_neg\n",
    "        df.at[(i,'vel_24_out_all')] = vel_24_out_all\n",
    "        df.at[(i,'vel_24_all')] = vel_24_in_all + vel_24_out_all\n",
    "        df.at[(i,'vel_48_in_pos')] = vel_48_in_pos\n",
    "        df.at[(i,'vel_48_in_neg')] = vel_48_in_neg\n",
    "        df.at[(i,'vel_48_in_all')] = vel_48_in_all\n",
    "        df.at[(i,'vel_48_out_pos')] = vel_48_out_pos\n",
    "        df.at[(i,'vel_48_out_neg')] = vel_48_out_neg\n",
    "        df.at[(i,'vel_48_out_all')] = vel_48_out_all\n",
    "        df.at[(i,'vel_48_all')] = vel_48_in_all + vel_48_out_all\n",
    "    print(f\"{(time.time() - start_time):.0f} seconds execution time\")\n",
    "    df.drop(['class'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df = m.feature_iteration_velocity(alpha_df)\n",
    "print(f\"{(time.time() - start_time):.0f} seconds execution time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import DateFormatter, DayLocator\n",
    "\n",
    "df2 = df[df['ratee']==7512].copy()\n",
    "df2.set_index('date', inplace=True)\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "ax.bar(df2.index.values,\n",
    "       df2['vel_24_all'],\n",
    "       color='purple')\n",
    "# ax = df2['vel_24_all'].plot(color='r', kind='bar', label='vel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(alpha_df['rater']==7512) | (df['ratee']==7512)].head()#[['date','vel_24_all','vel_24_in_all','vel_24_out_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df.groupby(['rater', 'date'])['rating'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_24_in_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df[(alpha_df['rater']==185) | (alpha_df['ratee']==185)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new collusion feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bitcoin_df_attibutes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_creation_collusion2(bitcoin_df, user, rate_date):\n",
    "    \"\"\" Returns array containing predictive features for \n",
    "    an individual bitcoin rating.\n",
    "    Input: \n",
    "        bitcoin_df:  Dataframe containing bitcoin ratings as edges\n",
    "        user: int\n",
    "        rate_date: date used for feature generation\n",
    "    Output:\n",
    "        array\n",
    "    \"\"\"\n",
    "    df = bitcoin_df.copy()\n",
    "    user_data_in = df[(df['ratee']==user) & ((df['date'] < rate_date) | ((df['date']==rate_date) & (df['rating'] > 0)))]\n",
    "    if len(user_data_in)==0:\n",
    "        return np.zeros(8)\n",
    "    \n",
    "    \n",
    "    num_ratings_received = len(user_data_in)\n",
    "    num_neg_received = user_data_in['class'].sum()\n",
    "    num_pos_received = num_ratings_received - num_neg_received\n",
    "    neg_ratings_pct = num_neg_received / num_ratings_received\n",
    "    rating_sum = user_data_in['rating'].sum()\n",
    "    days_active = (rate_date - user_data_in['date'].min()).days\n",
    "    _, g = h.build_graph(df, maxdate=rate_date)\n",
    "    cluster_coef = nx.clustering(g, user)\n",
    "    g = g.to_undirected()\n",
    "    num_cliques = nx.number_of_cliques(g, user)\n",
    "\n",
    "    A = np.array([num_ratings_received, num_neg_received, num_pos_received, \n",
    "                  neg_ratings_pct, rating_sum, days_active, cluster_coef, num_cliques])\n",
    "    A[np.isnan(A)] = 0\n",
    "    return A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
