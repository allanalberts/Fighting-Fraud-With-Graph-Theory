{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smote Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_params(X_train, y_train, X_test, y_test, RatioList, ScoringMethod, TimeIt=True):\n",
    "    \"\"\"\n",
    "    Returns the classifiers dictionary updated with 4 enties related to \n",
    "        SMOTE optimum parameter analysis. \n",
    "        SMOTE_grid - DataFrame containing smote analysis results for plotting\n",
    "        SMOTE_bestpart - \n",
    "        SMOTE_CVtrain_score - best search fit cross validate train score\n",
    "        SMOTE_test_score - best search fit test score\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clf - string, classifier to be analyzed\n",
    "    classifiers - dictionary\n",
    "    X_train, X_test - dataframes\n",
    "    y_train, y_test - dataSeries\n",
    "    RatioList - list, containing minority oversampling ratio values to test\n",
    "    ScoringMethod - string, metric to be optimized\n",
    "    TimeIt - boolean, flag for time processing time\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Classifiers: dictionay\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    steps = [('scaler', StandardScaler()),\n",
    "             ('SMOTE', SMOTE(random_state=SEED, n_jobs=CPU)),\n",
    "             ('Classifier', RandomForestClassifier()]        \n",
    "    pipeline = imb_Pipeline(steps)\n",
    "    parameters = {'SMOTE__sampling_strategy': RatioList}\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    searcher = GridSearchCV(pipeline, param_grid=parameters, cv=kf, scoring=ScoringMethod)\n",
    "    searcher.fit(X_train, y_train)\n",
    "    \n",
    "    df_gridCV = pd.DataFrame({'score': searcher.cv_results_['mean_test_score'],\n",
    "                              'ResampleRatio': RatioList })\n",
    "    \n",
    "    grid = df_gridCV\n",
    "    bestparm = searcher.best_params_['SMOTE__sampling_strategy']\n",
    "    CVtrain_score = searcher.best_score_\n",
    "    test_score = searcher.score(X_test, y_test)\n",
    "    if TimeIt:\n",
    "        t = time.time() - start_time\n",
    "        print(f\"{t:.0f} seconds execution time for {clf} classifier\")\n",
    " \n",
    "    return grid, bestparm, CVtrain_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, bestparm, CVtrain_score, test_score = smote_params\n",
    "\n",
    "def print_smote_parms():\n",
    "    print(f\"Best CV params {bestparm}\")\n",
    "    print(f\"Best CV value using training dataset: {CVtrain_score:.3f}\")\n",
    "    print(f\"Best grid search fit using testing dataset: {test_score:.3f}\\n\")   \n",
    "\n",
    "def plot_smote_parms(ax):\n",
    "    df_gridCV = SMOTE_grid \n",
    "    df_gridCV.plot(ax=ax, x='ResampleRatio');\n",
    "    ax.set_title(f\"{SMOTE Recall Scoring\")\n",
    "    ax.set_ylabel('Recall Score')\n",
    "\n",
    "def plot_smote_parms_dashboard(clf_lst, classifiers):\n",
    "    fig, axs = plt.subplots(1, len(clf_lst), figsize=(12,4), sharey=True)\n",
    "    i = 0\n",
    "    for clf in clf_lst:\n",
    "        plot_smote_parms(axs[i])\n",
    "        axs[i].plot(bestparm, \n",
    "                    CVtrain_score, \n",
    "                    'ko', label=\"Optimum\")\n",
    "        axs[i].legend(loc='lower right')\n",
    "        i += 1\n",
    " #   fig.savefig(\"../images/smote_parms.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, \\\n",
    "c_train, c_test, X_holdout, y_holdout, c_holdout, \\\n",
    "features = h.load_data(holdoutseed, engineered_features=False)\n",
    "print('Positive Class frequency: {:.5f}'.format(y_train.mean()))\n",
    "\n",
    "    RatioList = [0.002, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.10, 0.15, 0.20, 0.25]\n",
    "    ScoringMethod='recall'\n",
    "    clf_lst = [\"LR\", \"RF\", \"XGB\"]\n",
    "    for clf in clf_lst:\n",
    "        classifiers = smote_params(clf, classifiers, \n",
    "                                   X_train, y_train, \n",
    "                                   X_test, y_test, \n",
    "                                   RatioList, ScoringMethod, \n",
    "                                   TimeIt=True)\n",
    "\n",
    "    update_pipeline(clf_lst, classifiers)\n",
    "    h.save_classifier_dict(classifiers, \"04\")\n",
    "    print_smote_parms(clf_lst, classifiers)\n",
    "    plot_smote_parms_dashboard(clf_lst, classifiers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
