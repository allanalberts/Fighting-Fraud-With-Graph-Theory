{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import helpers as h\n",
    "import visualizations as v\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "otc_df = h.load_bitcoin_edge_data('../data/soc-sign-bitcoinotc.csv.gz')\n",
    "\n",
    "# Load preprocess features\n",
    "df_otc_features = pd.read_csv('../data/df_features_otc.csv')\n",
    "df_otc_velocity = pd.read_csv('../data/df_otc_vd.csv')\n",
    "\n",
    "merge_cols = ['ratee','rater','date','rating','class']\n",
    "features_df = pd.merge(df_otc_features, df_otc_velocity, on=merge_cols)\n",
    "features_df.drop(['binomial_rating', 'color', 'penwidth'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5297418630751964\n",
      "Precision: 0.8109965635738832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01860441, 0.03722324, 0.02184222, 0.11695053, 0.11888501,\n",
       "       0.09094446, 0.05163884, 0.05192537, 0.05446381, 0.09490893,\n",
       "       0.01630384, 0.01584243, 0.02450624, 0.0140141 , 0.02686423,\n",
       "       0.02545155, 0.02502995, 0.02722609, 0.02166095, 0.0226645 ,\n",
       "       0.05830643, 0.06474286])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features_df.copy()\n",
    "X = X.drop(['rater', 'ratee', 'rating','date'], axis=1)\n",
    "y = X.pop('class')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, shuffle=True,\n",
    "                                                    random_state=123)\n",
    "\n",
    "RF = RandomForestClassifier(n_jobs=-1, random_state=123)\n",
    "RF.fit(X_train, y_train)\n",
    "y_preds = RF.predict(X_test)\n",
    "recall = recall_score(y_test, y_preds)\n",
    "precision = precision_score(y_test, y_preds)\n",
    "\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "RF.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "name = \"Random Forest\"\n",
    "indices = np.argsort(RF.feature_importances_)[::-1][:40]\n",
    "ax1 = sns.barplot(y=X_train.columns[indices][:40],x = RF.feature_importances_[indices][:40] , orient='h')\n",
    "ax1.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "ax1.set_ylabel(\"Features\",fontsize=12)\n",
    "ax1.tick_params(labelsize=9)\n",
    "ax1.set_title(name + \" feature importance\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random grid to search for best hyperparameters - 100 different combinations, 3 fold cv\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, \n",
    "                               random_state=42, n_jobs = -1)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_random.fit(X_train, y_train)\n",
    "print(f\"{(time.time() - start_time):.0f} seconds execution time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 1000,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 10,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Best Random Search Model with Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "F1_score: 0.6402\n",
      "Recall score = 0.5241\n",
      "Precision score = 0.8222\n",
      "\n",
      "Model Performance:\n",
      "F1_score: 0.6570\n",
      "Recall score = 0.5342\n",
      "Precision score = 0.8530\n",
      "\n",
      "Improvement of 2.63%\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f\"Model Performance:\")\n",
    "    print(f\"F1_score: {f1:0.4f}\")\n",
    "    print(f\"Recall score = {recall:0.4f}\")\n",
    "    print(f\"Precision score = {precision:0.4f}\\n\")   \n",
    "    return f1\n",
    "base_model = RandomForestClassifier(oob_score=True, n_estimators=10, random_state=42)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_f1_score = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_f1_score = evaluate(best_random, X_test, y_test)\n",
    "\n",
    "improvement = (100 * (random_f1_score - base_f1_score) / base_f1_score)\n",
    "print(f\"Improvement of {improvement:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance:\n",
    "F1_score: 0.6402\n",
    "Recall score = 0.5241\n",
    "Precision score = 0.8222\n",
    "\n",
    "Model Performance:\n",
    "F1_score: 0.6570\n",
    "Recall score = 0.5342\n",
    "Precision score = 0.8530\n",
    "\n",
    "Improvement of 2.63%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 71.3min\n",
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed: 73.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4434 seconds execution time\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': [4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [3, 5, 7],\n",
    "    'n_estimators': [1000, 1200, 1400, 1600]}\n",
    "    \n",
    "rf = RandomForestClassifier(oob_score=True)\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"{(time.time() - start_time):.0f} seconds execution time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 15,\n",
       " 'max_features': 4,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'bootstrap': True,\n",
    " 'max_depth': 15,\n",
    " 'max_features': 4,\n",
    " 'min_samples_leaf': 3,\n",
    " 'min_samples_split': 7,\n",
    " 'n_estimators': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "F1_score: 0.6571\n",
      "Recall score = 0.5387\n",
      "Precision score = 0.8421\n",
      "\n",
      "Improvement of 2.64%\n",
      "\n",
      "Accuracy Score: 0.9437\n",
      "OOB Score: 0.9462\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_f1_score = evaluate(best_grid, X_test, y_test)\n",
    "\n",
    "improvement = (100 * (grid_f1_score - base_f1_score) / base_f1_score)\n",
    "print(f\"Improvement of {improvement:0.2f}%\")\n",
    "print(f\"\\nAccuracy Score: {grid_search.best_estimator_.score(X_test, y_test):0.4f}\")\n",
    "print(f\"OOB Score: {grid_search.best_estimator_.oob_score_:0.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance:\n",
    "F1_score: 0.6571\n",
    "Recall score = 0.5387\n",
    "Precision score = 0.8421\n",
    "\n",
    "Improvement of 2.64%\n",
    "\n",
    "Accuracy Score: 0.9437\n",
    "OOB Score: 0.9462"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
