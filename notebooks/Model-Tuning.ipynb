{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import networkx as nx\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import helpers as h\n",
    "import visualizations as v\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historical = pd.read_csv('../data/historical_features.csv')\n",
    "\n",
    "# Create Subset of High Value Rating Transactions\n",
    "mask = df_historical[(df_historical['num_neg_received']==0) & \n",
    "                        (df_historical['num_pos_received']>=3)]\n",
    "\n",
    "# Create Subset of High Value Rating Transactions with fraud but suspicious removed\n",
    "# df_mask = df_historical[(df_historical['num_neg_received']==0) & \n",
    "#                         (df_historical['num_pos_received']>=3) & \n",
    "#                         ((df_historical['rating']>0) | (df_historical['rating']==-10))]\n",
    "\n",
    "df_historical.drop(['color', 'penwidth'], inplace=True, axis=1)\n",
    "df_historical = df_historical[df_historical.index.isin(mask.index)]\n",
    "\n",
    "df_velocity = pd.read_csv('../data/velocity_features.csv')\n",
    "df_velocity.drop(['color', 'penwidth'], inplace=True, axis=1)\n",
    "df_velocity = df_velocity[df_velocity.index.isin(mask.index)]\n",
    "\n",
    "df_graph = pd.read_csv('../data/graph_features.csv')\n",
    "df_graph.drop(['color', 'penwidth'], inplace=True, axis=1)\n",
    "df_graph = df_graph[df_graph.index.isin(mask.index)]\n",
    "\n",
    "# Merge All Three Feature Categories\n",
    "merge_cols = ['ratee','rater','date','rating']\n",
    "dfs = [df_historical, df_velocity, df_graph]\n",
    "df_all = reduce(lambda left,right: pd.merge(left,right,on=merge_cols), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data \n",
    "# otc_df = h.load_bitcoin_edge_data('../data/soc-sign-bitcoinotc.csv.gz')\n",
    "\n",
    "# # Load preprocess features\n",
    "# df_otc_features = pd.read_csv('../data/df_features_otc.csv')\n",
    "# df_otc_velocity = pd.read_csv('../data/df_otc_vd.csv')\n",
    "\n",
    "# merge_cols = ['ratee','rater','date','rating','class']\n",
    "# features_df = pd.merge(df_otc_features, df_otc_velocity, on=merge_cols)\n",
    "# features_df.drop(['binomial_rating', 'color', 'penwidth'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all.copy()\n",
    "y = np.where(X['rating']<0, 1, 0) # set class as all negative ratings\n",
    "X = X.drop(['rater', 'ratee', 'rating', 'date'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.11450381679389313\n",
      "Precision: 0.5769230769230769\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_jobs=-1, random_state=123)\n",
    "RF.fit(X_train, y_train)\n",
    "y_preds = RF.predict(X_test)\n",
    "recall = recall_score(y_test, y_preds)\n",
    "precision = precision_score(y_test, y_preds)\n",
    "\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 17.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090 seconds execution time\n"
     ]
    }
   ],
   "source": [
    "# Random grid to search for best hyperparameters - 100 different combinations, 3 fold cv\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, scoring=make_scorer(recall_score),\n",
    "                               random_state=123, n_jobs = -1)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_random.fit(X_train, y_train)\n",
    "print(f\"{(time.time() - start_time):.0f} seconds execution time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 50,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 1000,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 10,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Best Random Search Model with Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allanalberts/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:540: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/allanalberts/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "F1_score: 0.2013\n",
      "Recall score = 0.1221\n",
      "Precision score = 0.5714\n",
      "\n",
      "Model Performance:\n",
      "F1_score: 0.1975\n",
      "Recall score = 0.1221\n",
      "Precision score = 0.5161\n",
      "\n",
      "Improvement of -1.85%\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f\"Model Performance:\")\n",
    "    print(f\"F1_score: {f1:0.4f}\")\n",
    "    print(f\"Recall score = {recall:0.4f}\")\n",
    "    print(f\"Precision score = {precision:0.4f}\\n\")   \n",
    "    return f1\n",
    "base_model = RandomForestClassifier(oob_score=True, n_estimators=10, random_state=123)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_f1_score = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_f1_score = evaluate(best_random, X_test, y_test)\n",
    "\n",
    "improvement = (100 * (random_f1_score - base_f1_score) / base_f1_score)\n",
    "print(f\"Improvement of {improvement:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance:\n",
    "F1_score: 0.6402\n",
    "Recall score = 0.5241\n",
    "Precision score = 0.8222\n",
    "\n",
    "Model Performance:\n",
    "F1_score: 0.6570\n",
    "Recall score = 0.5342\n",
    "Precision score = 0.8530\n",
    "\n",
    "Improvement of 2.63%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed: 29.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784 seconds execution time\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [45, 50, 55],\n",
    "    'max_features': [4, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'min_samples_split': [3, 5, 7],\n",
    "    'n_estimators': [1400, 1600, 1800]}\n",
    "    \n",
    "rf = RandomForestClassifier(oob_score=True)\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2, scoring=make_scorer(recall_score))\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"{(time.time() - start_time):.0f} seconds execution time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 55,\n",
       " 'max_features': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 1800}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### {'bootstrap': True,\n",
    " 'max_depth': 55,\n",
    " 'max_features': 5\n",
    " 'min_samples_leaf': 1\n",
    " 'min_samples_split': 3\n",
    " 'n_estimators': 1800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "F1_score: 0.1887\n",
      "Recall score = 0.1145\n",
      "Precision score = 0.5357\n",
      "\n",
      "Improvement of -6.25%\n",
      "\n",
      "Accuracy Score: 0.9713\n",
      "OOB Score: 0.9732\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_f1_score = evaluate(best_grid, X_test, y_test)\n",
    "\n",
    "improvement = (100 * (grid_f1_score - base_f1_score) / base_f1_score)\n",
    "print(f\"Improvement of {improvement:0.2f}%\")\n",
    "print(f\"\\nAccuracy Score: {grid_search.best_estimator_.score(X_test, y_test):0.4f}\")\n",
    "print(f\"OOB Score: {grid_search.best_estimator_.oob_score_:0.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance:\n",
    "F1_score: 0.6571\n",
    "Recall score = 0.5387\n",
    "Precision score = 0.8421\n",
    "\n",
    "Improvement of 2.64%\n",
    "\n",
    "Accuracy Score: 0.9437\n",
    "OOB Score: 0.9462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
